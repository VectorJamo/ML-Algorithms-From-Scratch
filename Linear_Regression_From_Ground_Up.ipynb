{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGb+SBaPGw1TK76nJrjfjw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VectorJamo/ML-Algorithms-From-Scratch/blob/main/Linear_Regression_From_Ground_Up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "ChsBxHA8YsD7"
      },
      "outputs": [],
      "source": [
        "# Implementing linear regression from scratch.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A linear regression model finds the line of best fit in n-dimensional space\n",
        "# The equation of this line in 2D is y = wx + b\n",
        "# In n-dimensional space, the equation is, y = w1(x1) + w2(x2) + w3(x3) + .... + w(n-1)x(n-1) + b\n",
        "\n",
        "def get_prediction(feature_vector, weight_vector, bias):\n",
        "  prediction = np.dot(feature_vector, weight_vector) + bias\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "p08XXFqLatDp"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It is our goal now to find the appropriate values of the weights and bias such that the cost of each training is minimized.\n",
        "# The cost function is the sum of the mean squared error(MSE) over the training data.\n",
        "# C = sum over the entire dataset(y(i) - ((w)x(i) + b))^2\n",
        "# Here, i = iterator going from 1 to N where N is the no. of data examples in the dataset. Each data example is a pair of (feature vector, output label)\n",
        "# x(i) is the feature vector, w is the weight vector, b is the bias and y(i) is the actual label for that training data.\n",
        "# Hence, this equation can be reduced as the square of the difference of the actual label and the predicted label by the model.\n",
        "# We wish to decrease the this value of the cost function overtime during training. Lesser the difference, we can see that better is our model is predicting\n",
        "# values that are closer to the actual values which is what we want.\n",
        "\n",
        "def get_total_training_cost(feature_vectors, output_labels, weight_vector, bias):\n",
        "  training_size = len(feature_vectors)\n",
        "  training_cost = 0\n",
        "  for i in range(0, training_size):\n",
        "    training_cost += (output_labels[i] - (np.dot(feature_vectors[i], weight_vector) + bias))**2\n",
        "\n",
        "  return training_cost"
      ],
      "metadata": {
        "id": "ZXg1FheBx0Pq"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Gradient Descent\n",
        "# Gradient Descent is a way of nudging the weights and biases in such a way that the cost of the the training decreases.\n",
        "# It consists of finding the gradient vector that points to the direction in which the function is decreasing and then taking steps in that direction.\n",
        "# When this process is done for many many times, we will eventually reach a local minimum where the cost function is minimized.\n",
        "\n",
        "# The equation for getting the derivative of the cost function with respect to the weight dC/dw is just the partial derivative of the cost function with\n",
        "# respect to the weight vector. Computing the partial derivative is trivial and can be done with a pen and paper.\n",
        "def get_weight_gradient(feature_vectors, output_labels, weight_vector, bias): # Returns dC/dw\n",
        "  weight_gradient = np.zeros(len(weight_vector))\n",
        "  training_size = len(feature_vectors)\n",
        "  for i in range(0, training_size):\n",
        "    weight_gradient += (-2 * (output_labels[i] - (np.dot(feature_vectors[i], weight_vector) + bias))) * feature_vectors[i]\n",
        "\n",
        "  return weight_gradient/training_size\n",
        "\n",
        "def get_bias_gradient(feature_vectors, output_labels, weight_vector, bias): # Returns dC/db\n",
        "  bias_gradient = 0\n",
        "  training_size = len(feature_vectors)\n",
        "  for i in range(0, training_size):\n",
        "    bias_gradient += ((-2 * (output_labels[i] - (np.dot(feature_vectors[i], weight_vector) + bias))))\n",
        "\n",
        "  return bias_gradient/training_size\n",
        "\n",
        "def perform_gradient_descent(feature_vectors, output_labels, weight_vector, bias):\n",
        "  dw = get_weight_gradient(feature_vectors, output_labels, weight_vector, bias)\n",
        "  db = get_bias_gradient(feature_vectors, output_labels, weight_vector, bias)\n",
        "  learning_rate = 0.05\n",
        "\n",
        "  weight_vector -= learning_rate * dw\n",
        "  bias -= learning_rate * db"
      ],
      "metadata": {
        "id": "5ybEQ6hk26Cg"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LRParameters():\n",
        "  def __init__(self):\n",
        "    self.weights = 0\n",
        "    self.bias = 0\n",
        "\n",
        "def train(feature_vectors, output_labels, epochs):\n",
        "  model_parameters = LRParameters()\n",
        "\n",
        "  # Initial model parameters\n",
        "  np.random.seed(40)\n",
        "  model_parameters.weights = np.random.rand(len(feature_vectors[0]))\n",
        "  model_parameters.bias = np.random.rand(1)\n",
        "  print(f'Initial weights: {model_parameters.weights}')\n",
        "  print(f'Initial bias: {model_parameters.bias}')\n",
        "\n",
        "  for i in range(0, epochs):\n",
        "    # Calculate the training cost\n",
        "    training_cost = get_total_training_cost(feature_vectors, output_labels, model_parameters.weights, model_parameters.bias)\n",
        "\n",
        "    # Perform gradient descent\n",
        "    perform_gradient_descent(feature_vectors, output_labels, model_parameters.weights, model_parameters.bias)\n",
        "\n",
        "    if i%10 == 0:\n",
        "      print(f'Training round: {i}. Training cost: {training_cost}')\n",
        "      print(f'Weights: {model_parameters.weights}. Bias: {model_parameters.bias}')\n",
        "      print('-------------------------------------------------------------------')\n",
        "\n",
        "  return model_parameters\n"
      ],
      "metadata": {
        "id": "SiRE_nMJ8R_0"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "feature_vectors = [[1], [2], [3], [4], [5]]\n",
        "output_labels = [[2], [4], [6], [8], [10]]\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "SfZ-T51k5dOx"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train(feature_vectors, output_labels, epochs)\n",
        "print(f'New weights: {model.weights}')\n",
        "print(f'New bias: {model.bias}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tjpCOu795uQ",
        "outputId": "d9c0befc-6f72-4526-d45d-a21962cef8a4"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights: [0.40768703]\n",
            "Initial bias: [0.05536604]\n",
            "Training round: 0. Training cost: [136.82085811]\n",
            "Weights: [2.14262149]. Bias: [0.52752333]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 10. Training cost: [0.13755363]\n",
            "Weights: [1.8941369]. Bias: [0.38219942]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 20. Training cost: [0.09781005]\n",
            "Weights: [1.91073106]. Bias: [0.32228919]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 30. Training cost: [0.06954964]\n",
            "Weights: [1.92472408]. Bias: [0.27176996]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 40. Training cost: [0.04945456]\n",
            "Weights: [1.93652367]. Bias: [0.22916968]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 50. Training cost: [0.03516558]\n",
            "Weights: [1.94647367]. Bias: [0.19324705]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 60. Training cost: [0.02500513]\n",
            "Weights: [1.95486399]. Bias: [0.16295533]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 70. Training cost: [0.01778036]\n",
            "Weights: [1.96193911]. Bias: [0.13741188]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 80. Training cost: [0.01264305]\n",
            "Weights: [1.9679052]. Bias: [0.1158724]\n",
            "-------------------------------------------------------------------\n",
            "Training round: 90. Training cost: [0.00899008]\n",
            "Weights: [1.9729361]. Bias: [0.09770926]\n",
            "-------------------------------------------------------------------\n",
            "New weights: [1.97678597]\n",
            "New bias: [0.08381]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "plt.axis([0, 10, 0, 10])\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Labels')\n",
        "plt.scatter(feature_vectors, output_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "vFORbYuO--BS",
        "outputId": "4b89d765-4657-4748-8e5b-52fe455ddfa2"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7c1425554280>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQFwD-unLvfk"
      },
      "execution_count": 159,
      "outputs": []
    }
  ]
}